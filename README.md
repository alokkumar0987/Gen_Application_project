# ðŸ§  Gen_Application_project

A powerful *Retrieval-Augmented Generation (RAG)* system with *Ollama LLM* and *Streamlit UI* for querying PDF documents.  
Upload PDFs, ask questions, and get instant answers in a clean web app.

---

## ðŸ“¸ Demo Screenshots
<img width="1920" height="1080" alt="Screenshot 2025-07-16 153135" src="https://github.com/user-attachments/assets/aa288fd4-3374-49c3-b88f-6aaf293c561a" />


<img width="1920" height="1080" alt="Screenshot 2025-07-16 153331" src="https://github.com/user-attachments/assets/8dd8f6bd-fd50-45d8-b4b0-67485813727f" />

---

## ðŸš€ Features
âœ… Load and process PDF documents  
âœ… Split text into smart chunks for better context  
âœ… Store embeddings in a Chroma Vector Database  
âœ… Query using LangChain + Ollama LLM (e.g., Llama 3.2)  
âœ… Streamlit Web App for easy Q&A  
âœ… Admit card PDFs in the data/ folder and Chatbot using local llm model   llama3.2

---

## ðŸ“¦ Folder Structure


Gen_Application_project/ â”œâ”€â”€ rag_system.py         # RAG pipeline (PDF loader â†’ Chroma DB â†’ Answering) â”œâ”€â”€ app.py                # Streamlit UI â”œâ”€â”€ requirements.txt      # Python dependencies â”œâ”€â”€ .gitignore            # Ignored files (chroma/, data/, venv/) â”œâ”€â”€ README.md             # Project description â”œâ”€â”€ data/                 # PDF files (ignored in Git) â”œâ”€â”€ chroma/               # Chroma DB (ignored in Git) â””â”€â”€ screenshots/          # App demo images
